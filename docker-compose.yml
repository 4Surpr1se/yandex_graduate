version: '3'
services:

  database:
    image: postgres:16.3
    env_file: 
      - .env
      - admin_panel/app/config/.env

    # only for debug
    #ports:
    #  - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
      - ./movies_database_dump.sql:/docker-entrypoint-initdb.d/dump.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U app -d movies_database" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    environment:
      - CLICKHOUSE_DB=default
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    restart: always

  backend:
    build: src
    # ports:
    #   - "80:80"
    env_file: 
      - .env
    depends_on:
      - database
    restart: always

  admin_panel:
    build: admin_panel/app
    expose:
      - "8000"
    env_file:
      - admin_panel/app/config/.env
    volumes:
      - staticfiles:/opt/app/staticfiles
    depends_on:
      database:
        condition: service_healthy
      elasticsearch:
        condition: service_started

  redis:
    image: redis:7.4.0
    #ports:
    #  - "6379:6379"
    restart: always

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    # only for debug
    #ports:
    #  - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    restart: always

  postgres_to_es:
    build: postgres_to_es
    env_file: 
      - .env
    depends_on:
      - database
      - elasticsearch
    volumes:
      - ./state.json:/app/state.json
      - ./logs:/app/logs
    restart: always

  nginx:
    image: nginx
    container_name: nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/site.conf:/etc/nginx/conf.d/site.conf
      - staticfiles:/static/
    logging:
        driver: gelf
        options:
          gelf-address: udp://127.0.0.1:5044
          tag: nginx Ñ‹

    depends_on:
      - backend
      - auth_service
      - admin_panel
    ports:
      - "80:80"

  tests:
    build: tests/functional
    env_file:
      - .env
    entrypoint: >
      sh -c "pip install --no-cache-dir -r requirements.txt
      && python3 utils/wait_for_redis.py
      && python3 utils/wait_for_es.py
      && python3 utils/wait_for_auth.py
      && pytest src"
    depends_on:
      - backend
      - elasticsearch
      - redis
      - auth_db
      - auth_redis
      - auth_service

  auth_db:
    image: postgres:16.3
    container_name: auth_postgres
    env_file:
      - auth_service/src/.env
    #ports:
    #  - "5433:5432"
    volumes:
      - ./auth_service/pg_auth_data:/var/lib/postgresql/data
      - ./auth_service/src/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U app -d auth" ]
      interval: 10s
      timeout: 5s
      retries: 5

  auth_redis:
    image: redis:7.4.0
    restart: always

  auth_service:
    build:
      context: .
      dockerfile: auth_service/src/Dockerfile
    container_name: auth_service
    env_file:
      - auth_service/src/.env
    volumes:
      - ./auth_service:/app  
      - ./auth_service/migrations:/app/migrations 
    ports:
      - "8000:8000"
    depends_on:
      auth_db:
        condition: service_healthy

  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "6831:6831/udp"
      - "16686:16686"
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411

  kafka-0:
    image: bitnami/kafka:3.4
    ports:
      - "9094:9094"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka-0:9092,EXTERNAL://127.0.0.1:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
    volumes:
      - kafka_0_data:/bitnami/kafka

  kafka-1:
    image: bitnami/kafka:3.4
    ports:
      - "9095:9095"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9095
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka-1:9092,EXTERNAL://127.0.0.1:9095
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
    volumes:
      - kafka_1_data:/bitnami/kafka

  kafka-2:
    image: bitnami/kafka:3.4
    ports:
      - "9096:9096"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=2
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9096
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka-2:9092,EXTERNAL://127.0.0.1:9096
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
    volumes:
      - kafka_2_data:/bitnami/kafka

  flask-app:
    build: ugc
    ports:
      - "5001:5001"
    volumes:
      - ./ugc:/app
    depends_on:
      - kafka-0
      - kafka-1
      - kafka-2

  ugc_etl:
    build: ugc_etl
    volumes:
      - ./ugc_etl:/app
    depends_on:
      - kafka-0
      - kafka-1
      - kafka-2
      - clickhouse

  logstash:
        image: logstash:8.10.2
        depends_on:
          - elk-elasticsearch
        environment:
          XPACK_MONITORING_ENABLED: "false"
          ES_HOST: "elk-elasticsearch:9200"
        ports:
          - "5044:5044/udp"
        volumes:
          - ./deploy/logstash.conf:/config/logstash.conf:ro
        command: logstash -f /config/logstash.conf

  elk-elasticsearch:
    image: elasticsearch:8.10.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - 9200:9200
    volumes:
      - ./deploy/esdata-elk:/usr/share/elasticsearch/data

  kibana:
    image: kibana:8.10.2
    ports:
      - "5601:5601"
    depends_on:
      - elk-elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elk-elasticsearch:9200

  user_activity_service:
    build: user_activity
    environment:
      - APP_ENV=production
      - SENTRY_DSN=https://95adc0c17c84f621c334181ba525bcaf@o4508200308965376.ingest.de.sentry.io/4508200312635472
    ports:
      - "8001:8001"
    depends_on:
      - mongo

  mongo:
    image: mongo:6
    container_name: mongo_user_act
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  filebeat:
      image: elastic/filebeat:8.10.2
      volumes:
        - /tmp/logs/nginx:/var/log/nginx:ro
        - ./deploy/filebeat.yml:/usr/share/filebeat/filebeat.yml
      depends_on:
        - nginx
        - logstash
        - elasticsearch
        - kibana
      links:
        - logstash

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"  # messages
      - "15672:15672"  # web
    env_file:
      - ./notification_api/.env

  notification_service:
    build: notification_worker
    ports:
      - "6789:6789" 

  notification_generator:
    build: notification_generator
    depends_on:
      - rabbitmq
      - notification_api

  notification_api:
    build:
      context: ./notification_api
    container_name: notification_api
    ports:
      - "8002:8000"
    depends_on:
      rabbitmq:
          condition: service_started
      notification_db:
          condition: service_healthy


  notification_db:
    image: postgres:16.3
    env_file:
      - ./notification_api/.env
    volumes:
      - ./notification_api/postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U user -d notification" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
#    ports:
#      - "5438:5432"


  admin_notification:
    build: ./admin_notification
    container_name: admin_notification
    ports:
      - "8008:8000"
    depends_on:
      - notification_api

  mailhog:
    image: mailhog/mailhog
    logging:
      driver: 'none'
    ports:
      - 1025:1025
      - 8025:8025

  billing_db:
    image: postgres:16.3
    container_name: billing_postgres
    env_file:
      - billing_service/.env
    ports:
      - "5434:5432"
    volumes:
      - ./billing_service/pg_billing_data:/var/lib/postgresql/data
      - ./billing_service/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U app -d billing_db" ]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  kafka_0_data:
  kafka_1_data:
  kafka_2_data:
  staticfiles:
  mongo_data:
  esdata:
    driver: local
  clickhouse_data:
